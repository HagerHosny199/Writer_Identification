{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import OS to share the project dir\n",
    "import os\n",
    "os.chdir('F:\\\\fourth_year\\Pattern_Classification\\project\\Writer_Identification') \n",
    "\n",
    "#import important packages\n",
    "from IAM_loader import IAM_loader\n",
    "#import tensorflow as tf\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import cv2 as cv2\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage import feature\n",
    "from operator import itemgetter\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import argrelextrema\n",
    "#packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "#allows charts to appear in the notebook \n",
    "%matplotlib inline\n",
    "\n",
    "#ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use IAM handwriting database download it first\n",
    "# here we will read the images and get the important info about the images \n",
    "# we divide the available images into (train,cv and test)\n",
    "# division will be depend on the number of the images \n",
    "\n",
    "training_data=[] # only the train \n",
    "training_data_threshold=[] #training black images \n",
    "test_data_threshold=[] #test black images \n",
    "validation_data=[] # cross validation \n",
    "test_data=[] # test images \n",
    "\n",
    "WIDTH=2175 #image width\n",
    "HEIGHT=2304 #image height\n",
    "path=\"../dataset/output2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reading_and_preprocess():\n",
    "    loader=IAM_loader('../dataset')\n",
    "    training_data,test_data,validation_data = loader.split_data()\n",
    "    #writting the data \n",
    "    training_data_threshold=training_data\n",
    "    test_data_threshold=validation_data\n",
    "    \n",
    "    #getting the thresholded images of the training\n",
    "    for i in range(len(training_data)):\n",
    "            temp=training_data[i][0]\n",
    "            _,image= cv2.threshold(temp,0,255,cv2.THRESH_BINARY_INV)\n",
    "            training_data_threshold[i][0]=image\n",
    "            \n",
    "    #getting the thresholded images of the test\n",
    "    for i in range(len(validation_data)):\n",
    "            temp=validation_data[i][0]\n",
    "            _,image= cv2.threshold(temp,0,255,cv2.THRESH_BINARY_INV)\n",
    "            test_data_threshold[i][0]=image\n",
    "    return training_data,test_data,validation_data,training_data_threshold,test_data_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the window that contains the words \n",
    "def crop_image(image,y1,y2,x1,x2):\n",
    "    image=image[y1:y2,x1:x2]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#note : use WIDTH and HEIGHT \n",
    "def resize_image (img):\n",
    "    img=cv2.resize(img, dsize=(HEIGHT, WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_lines(img):\n",
    "    horizontal_lines=[]\n",
    "    ret_lines=[] \n",
    "    #apply canny \n",
    "    edges = cv2.Canny(img,50,150,apertureSize = 3)\n",
    "    #dilation\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    img_dilation = cv2.dilate(edges, kernel, iterations=1)\n",
    "    #hough line transform\n",
    "    lines = cv2.HoughLinesP(img_dilation, 1, np.pi/180,200, maxLineGap=1,minLineLength=img.shape[1]/2)\n",
    "    #getting the horizontal lines \n",
    "    for i in range(len(lines)):\n",
    "           for line in lines[i]:\n",
    "                pt1 = (line[0],line[1])\n",
    "                pt2 = (line[2],line[3])\n",
    "                if (line[1]-line[3])==0 : #print((line[2]-line[3])//(line[0]-line[1]))\n",
    "                        cv2.line(img, pt1, pt2, (255,255,255), 3) \n",
    "                        horizontal_lines.append(line)\n",
    "    #sort lines to eleminate the closed lines \n",
    "    horizontal_lines=sorted(horizontal_lines,key=lambda x: x[1])\n",
    "    pt=horizontal_lines[0]\n",
    "    ret_lines.append(pt)\n",
    "    #loop to retrive the included lines \n",
    "    for i in range(1,len(horizontal_lines)):\n",
    "        if abs(horizontal_lines[i][1]-pt[1])>100:\n",
    "            #print(\"included\",horizontal_lines[i])\n",
    "            pt=horizontal_lines[i]\n",
    "            ret_lines.append(pt)\n",
    "    return ret_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_region():\n",
    "    for i in range(len(training_data)):\n",
    "        img=training_data[i][0]\n",
    "        lines=detect_lines(img)\n",
    "        print(len(lines))\n",
    "        print(img.shape,lines[1][1]+10,lines[2][1]-3,math.floor(lines[1][0]/4),img.shape[1]-1)\n",
    "        cropped_img=crop_image(img,lines[1][1]+10,lines[2][1]-3,math.floor(lines[1][0]/4),img.shape[1]-1)\n",
    "        cropped_img=resize_image(cropped_img)\n",
    "        training_data[i][0]=cropped_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_histogram(img):\n",
    "    histogram=[]\n",
    "    #loop through the image to calcultae the  horizontal histogram of the image\n",
    "    for i in range(img.shape[0]): #for each row\n",
    "        sum=0\n",
    "        for j in range(img.shape[1]): # for each col\n",
    "            if img[i][j]==0:\n",
    "                sum+=1\n",
    "        histogram.append(sum)\n",
    "    print(len(histogram),img.shape)\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image_histogram(hist, width,color='k'):\n",
    "    plt.plot(hist, color=color)\n",
    "    plt.xlim([0, width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_local_min(hist):\n",
    "    hist=np.array(hist)\n",
    "    local_minima=argrelextrema(hist, np.less)\n",
    "    return local_minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lines(img,hist,index):\n",
    "    prev_y=0\n",
    "    num=0\n",
    "    lines=[]\n",
    "    line_num=0\n",
    "    for i in range(len(hist)):\n",
    "        if ((i-prev_y)>0 and (num/(i-prev_y))>0.25 and hist[i]==0 and hist[i-1]!=hist[i] and i-prev_y>100) or ((i-prev_y)>0 and (num/(i-prev_y))>0.25 and hist[i]<20 and hist[i-1]<20 and hist[i-1]!=hist[i] and i-prev_y>100) :\n",
    "            temp=img[prev_y:i+5,0:img.shape[1]]\n",
    "            prev_y=i+5\n",
    "            num=0\n",
    "            #cv2.imwrite(\"../dataset/hager/line\"+str(index)+str(line_num)+\".png\",temp)\n",
    "            line_num+=1\n",
    "            lines.append(temp)\n",
    "        elif hist[i]>30:\n",
    "            num+=1\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def line_segmentation(img,num):\n",
    "    im = cv2.erode(img,np.ones((3,200), np.uint8))\n",
    "    im = cv2.medianBlur(im,5)\n",
    "    im = cv2.bitwise_not(im)\n",
    "    w= np.size(img,1)\n",
    "    # cv2.imshow(\"i\",cv2.resize(im,(700,500)))\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    lines = []\n",
    "    _,cnt,_ = cv2.findContours(im,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    for contour in cnt:\n",
    "        x=[c[0] for c in contour.reshape(-1,2)]\n",
    "        y=[c[1] for c in contour.reshape(-1,2)]\n",
    "        minx,miny,maxx,maxy=np.min(x),np.min(y),np.max(x),np.max(y)\n",
    "        if (maxx-minx)>=(0.8*w):\n",
    "            cv2.imwrite(\"../dataset/reem/line\"+str(num)+str(i)+\".png\",img[miny:maxy,minx:maxx])\n",
    "            lines.append(img[miny:maxy,minx:maxx])\n",
    "            i+=1\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding document a01-000u to the training data\n",
      "Adding document a01-003u to the training data\n",
      "Adding document a01-007u to the training data\n",
      "Adding document a01-011u to the training data\n",
      "Adding document a01-014u to the training data\n",
      "Adding document a01-020u to the training data\n",
      "Adding document a01-026u to the training data\n",
      "Adding document a01-030u to the training data\n",
      "Adding document a01-043u to the training data\n",
      "Adding document a01-049u to the training data\n",
      "Adding document a01-049x to the training data\n",
      "Adding document a01-053u to the training data\n",
      "Adding document a01-058u to the training data\n",
      "Adding document a01-063u to the training data\n",
      "Adding document a01-068u to the training data\n",
      "Adding document a01-072u to the training data\n",
      "Adding document a01-077u to the training data\n",
      "Adding document a01-082u to the training data\n",
      "Adding document a01-087u to the training data\n",
      "Adding document a01-091u to the training data\n",
      "Adding document a01-096u to the training data\n",
      "Adding document a01-102u to the training data\n",
      "Adding document a01-107u to the training data\n",
      "Adding document a01-113u to the training data\n",
      "Adding document a01-117u to the training data\n",
      "Adding document a01-122u to the training data\n",
      "Adding document a01-128u to the training data\n",
      "Adding document a01-132u to the training data\n",
      "Adding document a01-132x to the training data\n",
      "Adding document a01-132u to the validation data\n",
      "Adding document a01-132x to the validation data\n",
      "Adding document a01-000x to the training data\n",
      "Adding document a01-072x to the test data\n",
      "document a01-003 was splitted \n",
      "Adding document a01-003x to the training data\n",
      "Adding document a01-007x to the test data\n",
      "document a01-007 was splitted \n",
      "Adding document a01-011 to the training data\n",
      "Adding document a01-030 to the test data\n",
      "document a01-011x was splitted \n",
      "Adding document a01-014 to the training data\n",
      "Adding document a01-038 to the test data\n",
      "Adding document a01-014x to the training data\n",
      "Adding document a01-026x to the test data\n",
      "Adding document a01-020 to the training data\n",
      "Adding document a01-026 to the test data\n",
      "Adding document a01-020x to the training data\n",
      "Adding document a01-030x to the test data\n",
      "Adding document a01-038x to the training data\n",
      "Adding document a01-043x to the test data\n",
      "Adding document a01-043 to the training data\n",
      "Adding document a01-049 to the test data\n",
      "Adding document a01-053 to the training data\n",
      "Adding document a01-058 to the test data\n",
      "Adding document a01-053x to the training data\n",
      "Adding document a01-058x to the test data\n",
      "document a01-063x was splitted \n",
      "Adding document a01-077 to the training data\n",
      "Adding document a01-091 to the test data\n",
      "document a01-087 was splitted \n",
      "Adding document a01-107 to the training data\n",
      "Adding document a01-113 to the test data\n",
      "Adding document a01-117 to the training data\n",
      "Adding document a01-122 to the test data\n",
      "document a01-132 was splitted \n",
      "document a02-000 was splitted \n",
      "document a02-004 was splitted \n",
      "document a02-008 was splitted \n",
      "document a02-012 was splitted \n",
      "Adding document a02-017 to the training data\n",
      "Adding document a02-020 to the training data\n",
      "Adding document a02-024 to the training data\n",
      "Adding document a02-027 to the training data\n",
      "Adding document a02-032 to the training data\n",
      "Adding document a02-027 to the validation data\n",
      "Adding document a02-032 to the validation data\n",
      "Adding document a02-037 to the training data\n",
      "Adding document a02-042 to the test data\n",
      "document a02-046 was splitted \n",
      "document a02-050 was splitted \n",
      "document a02-053 was splitted \n",
      "document a02-057 was splitted \n",
      "document a02-062 was splitted \n",
      "document a02-067 was splitted \n",
      "document a02-072 was splitted \n"
     ]
    }
   ],
   "source": [
    "training_data,test_data,validation_data,training_data_threshold,test_data_threshold=reading_and_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(3542, 2479) 614 2786 217 2478\n",
      "3\n",
      "(3542, 2479) 716 2788 179 2478\n",
      "3\n",
      "(3542, 2479) 664 2786 183 2478\n",
      "3\n",
      "(3542, 2479) 663 2785 208 2478\n",
      "3\n",
      "(3542, 2479) 664 2786 198 2478\n",
      "3\n",
      "(3542, 2479) 666 2787 165 2478\n",
      "3\n",
      "(3542, 2479) 714 2787 220 2478\n",
      "3\n",
      "(3542, 2479) 714 2786 171 2478\n",
      "3\n",
      "(3542, 2479) 663 2785 177 2478\n",
      "3\n",
      "(3542, 2479) 711 2784 211 2478\n",
      "3\n",
      "(3542, 2479) 734 2804 81 2478\n",
      "3\n",
      "(3542, 2479) 711 2784 185 2478\n",
      "3\n",
      "(3542, 2479) 662 2785 221 2478\n",
      "3\n",
      "(3542, 2479) 664 2787 196 2478\n",
      "3\n",
      "(3542, 2479) 662 2785 198 2478\n",
      "3\n",
      "(3542, 2479) 663 2786 185 2478\n",
      "3\n",
      "(3542, 2479) 661 2785 229 2478\n",
      "3\n",
      "(3542, 2479) 763 2787 172 2478\n",
      "3\n",
      "(3542, 2479) 662 2785 187 2478\n",
      "3\n",
      "(3542, 2479) 663 2786 225 2478\n",
      "3\n",
      "(3542, 2479) 713 2787 198 2478\n",
      "3\n",
      "(3542, 2479) 664 2787 208 2478\n",
      "3\n",
      "(3542, 2479) 613 2786 225 2478\n",
      "3\n",
      "(3542, 2479) 715 2789 85 2478\n",
      "3\n",
      "(3542, 2479) 711 2786 223 2478\n",
      "3\n",
      "(3542, 2479) 662 2786 225 2478\n",
      "3\n",
      "(3542, 2479) 713 2787 169 2478\n",
      "3\n",
      "(3542, 2479) 662 2785 206 2478\n",
      "3\n",
      "(3542, 2479) 688 2805 80 2478\n",
      "3\n",
      "(3542, 2479) 635 2803 81 2478\n",
      "3\n",
      "(3542, 2479) 721 2799 83 2478\n",
      "3\n",
      "(3542, 2479) 738 2807 81 2478\n",
      "3\n",
      "(3542, 2479) 671 2797 144 2478\n",
      "3\n",
      "(3542, 2479) 672 2797 195 2478\n",
      "3\n",
      "(3542, 2479) 688 2805 84 2478\n",
      "3\n",
      "(3542, 2479) 672 2799 186 2478\n",
      "3\n",
      "(3542, 2479) 686 2804 82 2478\n",
      "3\n",
      "(3542, 2479) 672 2799 166 2478\n",
      "3\n",
      "(3542, 2479) 686 2803 79 2478\n",
      "3\n",
      "(3542, 2479) 736 2803 84 2478\n",
      "3\n",
      "(3542, 2479) 672 2799 185 2478\n",
      "3\n",
      "(3542, 2479) 721 2799 214 2478\n",
      "3\n",
      "(3542, 2479) 735 2803 81 2478\n",
      "3\n",
      "(3542, 2479) 688 2806 83 2478\n",
      "3\n",
      "(3542, 2479) 669 2796 82 2478\n",
      "3\n",
      "(3542, 2479) 673 2799 202 2478\n",
      "3\n",
      "(3542, 2479) 622 2797 147 2478\n",
      "3\n",
      "(3542, 2479) 719 2797 86 2478\n",
      "3\n",
      "(3542, 2479) 671 2797 185 2478\n",
      "3\n",
      "(3542, 2479) 671 2796 83 2478\n",
      "3\n",
      "(3542, 2479) 723 2798 84 2478\n",
      "3\n",
      "(3542, 2479) 719 2796 82 2478\n",
      "3\n",
      "(3542, 2479) 721 2798 80 2478\n",
      "3\n",
      "(3542, 2479) 617 2800 201 2478\n",
      "3\n",
      "(3542, 2479) 565 2798 189 2478\n",
      "3\n",
      "(3542, 2479) 617 2800 86 2478\n",
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ed7310ceebfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-1f103413c2cf>\u001b[0m in \u001b[0;36mget_region\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetect_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mcropped_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcrop_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mcropped_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresize_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "get_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "for i in range(55):\n",
    "    img=training_data[i][0]\n",
    "    #convert to gray scale\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #getting the binary image\n",
    "    ret,img = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "    #calculate the histogram\n",
    "    hist=get_histogram(img)\n",
    "    local_min=get_local_min(hist)\n",
    "    local_min=local_min[0].ravel()\n",
    "    get_lines(img,hist,i)\n",
    "    _=line_segmentation(img,i)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2175 (2175, 2304)\n",
      "217 (217, 2304)\n"
     ]
    }
   ],
   "source": [
    "img=training_data[0][0]\n",
    "#convert to gray scale\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#getting the binary image\n",
    "ret,img = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "#calculate the histogram\n",
    "hist=get_histogram(img)\n",
    "lines=get_lines(img,hist,i)\n",
    "line_hist=get_histogram(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 (217, 2304)\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 7, 8, 8, 8, 24, 34, 37, 43, 47, 52, 53, 56, 67, 73, 85, 93, 95, 102, 105, 105, 107, 122, 132, 146, 164, 174, 180, 196, 190, 212, 224, 239, 248, 270, 278, 297, 318, 359, 425, 472, 495, 517, 517, 524, 523, 511, 487, 470, 475, 473, 475, 471, 480, 506, 506, 501, 502, 488, 518, 516, 470, 478, 484, 444, 386, 315, 247, 200, 131, 85, 59, 52, 34, 19, 19, 19, 20, 19, 20, 18, 17, 15, 12, 8, 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xt0VPXd7/H3NwlBuSVALnKRcpED\nKkskRi5qfVQEQStSW1G0FZ+jpaJdrUV7Sq21j8u66oVHrR6rUsHipRWtWPBKUOCUSkECJshNQMCC\nxIRbQkKEhOR3/pg9PAESMoTJ7D2Tz2utrMzs2Zn5sBM++eU3+2LOOUREJHEl+R1ARESal4peRCTB\nqehFRBKcil5EJMGp6EVEEpyKXkQkwanoRUQSnIpeRCTBqehFRBJcit8BADIyMlzPnj39jiEiEldW\nrFixyzmX2dh6gSj6nj17kp+f73cMEZG4YmZfRrKepm5ERBKcil5EJMGp6EVEEpyKXkQkwanoRUQS\nnIpeRCTBqehFRBKcil5E4s4nn3zCM888w+rVq/2OEhcCccCUiEikysvLGTt2LEVFRQC8+eabXHvt\ntT6nCjaN6EUkrjz00EMUFRXx1ltv0aNHD1544YWoPv+BAwf48suIDjiNGyp6EYkL9913H71792bq\n1KlMmDCBsWPHcv311zN//nx2794dtdd59NFH6dmzJ1ddddXhvxrinYpeROLCn//8Z1q1asUdd9zB\n1KlTAbj++us5dOgQb731VtRep7CwkPT0dObNm8fTTz8dtef1k4peRAJv9+7dfPXVV9x222089dRT\nZGRkAJCTk8MZZ5zBrFmzovZaX3zxBRdeeCFdunRhx44dUXteP6noRSTwVq1aBcA555xzxHIz4+qr\nr2bx4sXU1NSc9Os45/jiiy/o06cP2dnZlJSUnPRzBkFERW9mW83sMzMrMLN8b1knM5tvZhu9zx29\n5WZmT5nZJjNbZWY5zfkPEJHEFy76gQMHHvPYOeecw8GDB/niiy8ieq7du3dz3XXXMXr06MNTQGE7\nd+6koqLicNEXFxeffPgAOJER/aXOuXOdc7ne/SnAR865vsBH3n2A0UBf72Mi8Gy0wopIy1RYWEhm\nZibZ2dnHPDZgwACAiPepX7BgAX/729/YsGEDv/jFL5g2bRo7d+5k165dh39Z9OnTh6ysrBZZ9Ee7\nBpjp3Z4JjK2z/CUXshRIN7MuJ/E6ItLCrVq1ioEDB2Jmxzx25plnYmasWbMmoudav349AAUFBYwa\nNYrbb7+drKwszj//fDZt2gRwxNSNcy56/xCfRFr0DsgzsxVmNtFblu2cKwLwPmd5y7sB2+p87XZv\n2RHMbKKZ5ZtZ/s6dO5uWXkQS3qFDh1i9evUx8/Nhbdu2pVevXhGP6NetW8e3vvUt2rdvz1//+lcm\nTpzIuHHj2Lp1K7Nnz8bM6NWrF9nZ2VRXV1NaWhrNf44vIi36C51zOYSmZe40s4uPs+6xv3JDvyiO\nXODcNOdcrnMuNzOz0UseikgLtXHjRg4ePFjv/HzYgAEDIi769evXc+aZZwKQnp7Oc889x1NPPQXA\n3Llz6d69O61btz48TZQI0zcRFb1zbof3uQR4CxgMFIenZLzP4bentwOn1/ny7kBi7KMkIjFXWFgI\nHLvHTV0DBgxgw4YNVFVVHfe5amtr+fzzz+nfv/8Ry7Ozszn//POpra2ld+/eAGRlhSYpWkTRm1lb\nM2sfvg2MBFYDc4EJ3moTgDne7bnAzd7eN0OBsvAUj4jIiVq1ahUpKSmHR+H1Ofvsszl06BAbNmw4\n7nNt376dysrKY4oe4KqrrgJC8/NAixvRZwP/NLNC4BPgXefcB8DDwAgz2wiM8O4DvAdsBjYBfwLu\niHpqEWkxCgsL6d+/P61bt25wnUj3vFm3bh3ACRV9IuxL3+jZK51zm4FjJsecc7uB4fUsd8CdUUkn\nIi1eYWEhl1xyyXHX6devH6mpqeTn53PDDTc0uF54j5v6/jo477zzePrppw+fCbNz584kJSUdHtHv\n37+fBQsWcPXVVzfxX+IfHRkrIoEVPvXB8d6IBWjdujVDhgxh8eLFx11v/fr1dOzYkfp2ADEzfvKT\nn9C1a1cAkpOTycjIOFz0t99+O2PGjGl0eiiIVPQiElgNnfqgPt/+9rdZsWIFFRUVx32+fv361bs/\nfn3CR8fOnj2bV155BYBt27Y18lXBo6IXkcA63qkPjnbxxRdTU1PD0qVLjzjIyTmHc47Vq1ezZMmS\nw3PxkcjOzmbLli3ccccddO/eHSAuT3SmK0yJSGAd79QHRxs2bBhJSUm89tpr/PjHP6Zbt25cfvnl\nTJs2jSFDhnDKKadw6qmnMmnSpIhfPzs7mw8//BCAvLw8Ro4cqaIXEYmmzz77jHPOOSeiqZYOHTow\naNAgpk+fTtu2bamqquK3v/0tOTk5zJ49G4A777yTzp07R/z64X3pR40axYgRI+jQoQNfffVV0/4x\nPtLUjYgE1rZt2w4fwBSJ8N45L7/8Mps2bWLz5s2sWLGCP/3pT/Tt25e77777hF6/R48eADzwwAMA\ndO3aNS5H9BaEE/bk5ua6/Px8v2OISIDU1NSQmprKvffey4MPPhjR1+zdu5f169czbNiwqGSoqKhg\n9erVDB06FIDhw4fzzTffsGTJkqg8/8kysxV1zijcII3oRSSQ9uzZQ21t7eHpk0h07NgxaiUP0K5d\nu8MlD/E7olfRi0gghY9IPZGib27dunVjx44dcXfqYhW9iARSEIu+a9euVFdXs3v3br+jnBAVvYgE\nUviI1Eh2rYyV8FGz8TZ9o6IXkUAK6ogeiLtdLFX0IhJIJSUlJCcn06lTJ7+jHKYRvYhIFJWUlJCZ\nmUlSUnBqqkuX0OWvVfQiIlFQXFwcqGkbCJ0lMyMjQ0UvIhINJSUlgSt6CI3qi4ri66J5KnoRCaSg\nFn3nzp3Zs2eP3zFOiIpeRAKpuLg4ULtWhnXq1ElFLyJysvbv38/+/fsDOaJX0YuIRMHOnTuBYO1D\nHxYu+ng6DYKKXkQCJ3ywVFCnbg4ePMg333zjd5SIqehFJHDCpz8I6ogeiKvpGxW9iAROeOomMzPT\n5yTHUtGLiETB3r17AQJ1+oMwFb2ISBSUlpaSlJREu3bt/I5yDBW9iEgUlJaWkpaWFqjz3ISp6EVE\noqCsrIz09HS/Y9QrXPTxdPERFb2IBE54RB9Ebdq0ITU1NTFH9GaWbGafmtk73v1eZrbMzDaa2Swz\nS/WWt/bub/Ie79k80UUkUZWWlgZ2RG9mcXe+mxMZ0f8MWFfn/iPAE865vsBe4FZv+a3AXufcGcAT\n3noiIhELctFD/J0GIaKiN7PuwFXAC959Ay4D/uatMhMY692+xruP9/hwb30RkYio6KMr0hH9k8D/\nAWq9+52BUufcIe/+dqCbd7sbsA3Ae7zMW19EJCIq+uhqtOjN7DtAiXNuRd3F9azqInis7vNONLN8\nM8sPHwUnInLo0CHKy8tV9FEUyYj+QmCMmW0FXiM0ZfMkkG5mKd463YHwtbW2A6cDeI+nAcdsEefc\nNOdcrnMuN4iHOYuIP/bt2wegoo+iRoveOfcr51x351xP4AZggXPuJmAh8H1vtQnAHO/2XO8+3uML\nXDydz1NEfFVWVgYQ2N0rIVT0lZWVHDhwwO8oETmZ/eh/CUw2s02E5uCne8unA5295ZOBKScXUURa\nktLSUiD4I3r4n3PyBF1K46v8D+fcImCRd3szMLiedQ4A10Uhm4i0QPFU9Hv27KFLly4+p2mcjowV\nkUCJh6Lv2LEjED/nu1HRi0igxEPRh98/CL+fEHQqehEJFBV99KnoRSRQSktLMTM6dOjgd5QGqehF\nRE5CaWkpHTp0COS56MPCf22o6EVEmqCsrCzQ+9ADnHLKKaSmpqroRUSaIujnuQlLS0tT0YuINIWK\nPvpU9CISKCr66FPRi0igqOijT0UvIoGyZ88eFX2UqehFJDD2799PeXl5XJw/RkUvItIERUVFACr6\nKFPRi0hghIu+a9euPidpXFpaGvv27aOmpsbvKI1S0YtIYOzYEbpQXbyM6AHKy8t9TtI4Fb2IBEa8\njeghPk6DoKIXkcDYsWMHrVu3Pny+9yBT0YuINMGOHTvo0qULZuZ3lEap6EVEmqCoqCgupm1ARS8i\n0iThEX08UNGLiDRBPI3o4+mc9Cp6EQmEyspKysrKNKJvBip6EQmEeNq1EuLr4iMqehEJhPDBUvFS\n9BA/p0FQ0YtIIMTTeW7CVPQiIidAI/rmo6IXkUBYt24d6enpcXFUbJiKXkTkBKxcuZKcnJy4OCo2\nLC0tjdLSUr9jNEpFLyK+q66uZtWqVeTk5Pgd5YQkzIjezE4xs0/MrNDM1pjZA97yXma2zMw2mtks\nM0v1lrf27m/yHu/ZvP8EEYl3a9eupaqqSkXfTCIZ0R8ELnPODQTOBUaZ2VDgEeAJ51xfYC9wq7f+\nrcBe59wZwBPeeiIiDVq5ciVAXBZ9eXl54C8+0mjRu5AK724r78MBlwF/85bPBMZ6t6/x7uM9Ptzi\nadJNRGJu5cqVtGvXjr59+/od5YTEy8VHIpqjN7NkMysASoD5wBdAqXPukLfKdqCbd7sbsA3Ae7wM\n6BzN0CKSWD799FMGDhxIUlJ8vW0YL6dBiGirOudqnHPnAt2BwcCZ9a3mfa5v9O6OXmBmE80s38zy\nd+7cGWleEUkwNTU1FBQUxN20DSRY0Yc550qBRcBQIN3MUryHugM7vNvbgdMBvMfTgD31PNc051yu\ncy43MzOzaelFJO6tXbuW/fv3k5ub63eUE5YwRW9mmWaW7t0+FbgcWAcsBL7vrTYBmOPdnuvdx3t8\ngXPumBG9iAjAsmXLABgyZIjPSU5cvJyqOKXxVegCzDSzZEK/GF53zr1jZmuB18zsd8CnwHRv/enA\ny2a2idBI/oZmyC0iCWLZsmV07Ngx7t6IhfgZ0Tda9M65VcCgepZvJjRff/TyA8B1UUknIglv2bJl\nDB48OO7eiIX4Kfr427IikjAqKipYs2ZNXE7bgIpeRKRR+fn51NbWxm3Rx8vFR1T0IuKbpUuXAjB4\n8DGzwHEjHk6DoKIXEV9UVVXx/PPPM3jwYDIyMvyO02TxUPSR7HUjIhJ1L774Ilu3buWPf/yj31FO\nSjycqlgjehGJuerqan73u98xbNgwRo0a5XeckxIPI3oVvYjE3KpVq9i+fTs//elP4+pCI/VR0YuI\n1KOgoAAgLk97cDQVvYhIPQoLC2nXrh29e/f2O8pJU9GLiNSjoKCAc845Jy6Phj1aPFx8JP63sojE\nFecchYWFnHvuuX5HiYp4uPiIil5EYmrr1q3s27cv4Yo+yNM3KnoRianwG7EDBw70OUl0qOhFRI5S\nUFBAUlISAwYM8DtKVMTDOelV9CISM8453n//fQYMGECbNm38jhMV4RF9kI+OVdGLSMwsXryY5cuX\nM2nSJL+jRE34PD27du3yOUnDVPQiEjNTp04lIyODm2++2e8oUZOVlQVASUmJz0kapqIXkZjYvHkz\nb7/9NnfeeWfCTNsAtG3blrZt26roRUTee+89AH74wx/6nCT6srKyKC4u9jtGg1T0IhITeXl59O7d\nmz59+vgdJeqysrI0oheRlq26upqFCxcycuRIv6M0i+zsbBW9iLRsS5cupaKiImGLXiN6EWnx8vLy\nSE5O5tJLL/U7SrMIF31tba3fUeqloheRZvfOO+8wZMiQw0eRJpqsrCxqamrYu3ev31HqpaIXkWa1\nYcMGCgoK+P73v+93lGaTnZ0NBHdfehW9iDSrWbNmYWaMGzfO7yjNJnzQVFB3sVTRi0izmjVrFhdd\ndBHdunXzO0qzCfrRsSp6EWk2a9euZc2aNVx//fV+R2lWKnoRabE+/vhjAEaNGuVzkubVuXNnkpKS\n4rfozex0M1toZuvMbI2Z/cxb3snM5pvZRu9zR2+5mdlTZrbJzFaZWU5z/yNEJJgKCwtp3749vXr1\n8jtKs0pOTiYjIyOu5+gPAXc7584EhgJ3mtlZwBTgI+dcX+Aj7z7AaKCv9zEReDbqqUUkLhQUFDBw\n4MCEuAh4Y4J80FSjW985V+ScW+ndLgfWAd2Aa4CZ3mozgbHe7WuAl1zIUiDdzLpEPbmIBFptbW1C\nXQS8MUE+DcIJ/Zo1s57AIGAZkO2cK4LQLwMgy1utG7Ctzpdt95Yd/VwTzSzfzPJ37tx54slFJNC2\nbNlCRUVFwlwbtjGZmZnxX/Rm1g54E7jLObfveKvWs8wds8C5ac65XOdcbmZmZqQxRCTg1q9fz7hx\n41iwYAFAixnRp6enB/a6sSmRrGRmrQiV/KvOudne4mIz6+KcK/KmZsK/yrYDp9f58u7AjmgFFpFg\ne/nll3njjTd49913SU5O5uyzz/Y7UkykpaVRWlqKcw6z+sa7/olkrxsDpgPrnHOP13loLjDBuz0B\nmFNn+c3e3jdDgbLwFI+IJL4FCxbQqlUrKisr6devH6eeeqrfkWIiLS2N6upqDhw44HeUY0Qyor8Q\n+CHwmZkVeMvuBR4GXjezW4F/A9d5j70HXAlsAiqB/4xqYhEJrPLycpYvX84999zDihUryM3N9TtS\nzKSlpQFQVlYWuF9ujRa9c+6f1D/vDjC8nvUdcOdJ5hKROLR48WJqamoYMWIEDz/8sN9xYip8Zs6y\nsjJOO+00n9McKfF3bhWRmFm4cCGpqalccMEFfkeJuboj+qBR0YtIVDjnyMvLY+jQoYGbuogFFb2I\nJLwXXniBVatWcdNNN/kdxRfhoi8tLfU5ybFU9CJy0rZs2cLkyZMZPnw4t912m99xfKERvYgktN//\n/vfU1NQwY8aMFnFem/qo6EUkYZWVlfHqq68yfvx4evTo4Xcc37Rv3x4zU9GLSOJ55ZVXqKysZNKk\nSX5H8VVSUhIdOnRQ0YtI4nnuuefIzc1tUQdHNSR8GoSgUdGLSJNt27aN1atX84Mf/MDvKIGQlpam\nEb2IJJYlS5YAcNFFF/mcJBhU9CKScJYsWUKbNm1azDnnGxPUUxWr6EWkyZYsWcKQIUNISYnojOcJ\nTyN6EUko+/fv59NPP22R57VpiIpeRBLK8uXLqampUdHXUffiI0GioheRJvn4448BGDp0qM9JgiMt\nLY2amhoqKyv9jnIEFb2INMm8efM499xz6dSpk99RAiOop0FQ0YvICdu7dy9Llizhqquu8jtKoNS9\n+EiQqOhF5ITNmzePmpoaFf1RNKIXkYTx7rvvkpGRweDBg/2OEigqehFJCDU1NXzwwQeMGjWK5ORk\nv+MESlAvPqKiF5ET8sEHH7Br1y7Gjh3rd5TACc/Rq+hFJK49++yznHbaaYwZM8bvKIGTmZkJQElJ\nic9JjqSiF5GIbd26lffee4/bbruNVq1a+R0ncFJTU0lPT6e4uNjvKEdQ0YtIxKZPn46Z8aMf/cjv\nKIGVnZ2tEb2IxK+3336biy++uEVfMrAx2dnZGtGLSHz6+uuvKSws5IorrvA7SqCp6EUkbn344YcA\njBgxwuckwaaiF5G4lZeXR+fOnRk0aJDfUQItKyuL0tJSqqqq/I5ymIpeRBrlnCMvL48RI0aQlKTa\nOJ7s7GwgWLtYNnpZGDObAXwHKHHODfCWdQJmAT2BrcA459xeMzPgD8CVQCVwi3NuZfNEF5HmVFFR\nwSuvvEJFRQVz586luLiYK6+80u9YgRcu+uLiYrp37+5zmpBIrv/1Z+D/Ai/VWTYF+Mg597CZTfHu\n/xIYDfT1PoYAz3qfRSSOFBYWMm7cODZs2ABAt27d+MMf/sBNN93kc7Lgq1v0QdFo0Tvn/mFmPY9a\nfA1wiXd7JrCIUNFfA7zkQpdXWWpm6WbWxTlXFK3AItK8ysvLGT16NGbGhx9+yPnnn0/btm11XpsI\nZWVlAXE2ddOA7HB5O+eKzCzLW94N2FZnve3esmOK3swmAhMB7ZMrEiAPPfQQRUVFLF26lCFD9Af5\niQriiD7a76pYPcvqvXiic26acy7XOZcbPj+EiPintraW2bNn8/jjjzNhwgSVfBO1bduWtm3bJkTR\nF5tZFwDvc/hvlO3A6XXW6w7saHo8EYkF5xyjR4/me9/7Hr169eLhhx/2O1JcC9q+9E0t+rnABO/2\nBGBOneU3W8hQoEzz8yLBN2fOHPLy8njwwQdZs2YNp512mt+R4lrQij6S3Sv/SuiN1wwz2w78FngY\neN3MbgX+DVznrf4eoV0rNxHavfI/myGziERRbW0t999/P3379mXKlCmkpDT1rTsJy8rKYvPmzX7H\nOCySvW7GN/DQ8HrWdcCdJxtKRGJnzpw5fPbZZ7z66qsq+SjJzs5myZIlfsc4TIe4ibRwM2fOpGvX\nrlx//fV+R0kYvXr1YufOnZSXl/sdBVDRi7RoZWVlvP/++1x33XXaTz6K+vfvD8D69et9ThKiohdp\nwebMmUNVVZVG81GmoheRwJg1axY9evRg6NChfkdJKH369CElJUVFLyL+Wrp0KR988AE33ngjofMR\nSrS0atWKM844Q0UvIv6prKxkwoQJdO/enV/96ld+x0lI/fv3Z926dX7HAFT0Ii3S1KlT2bBhAy++\n+CIdOnTwO05C6t+/P5s2baK6utrvKCp6kZamtraWGTNmMGLECC677DK/4ySsM888k+rqarZs2eJ3\nFBW9SEvzj3/8gy+//JIJEyY0vrI0WZD2vFHRi7QwM2fOpH379nz3u9/1O0pC69evHwCLFy/2OYmK\nXqRFmT9/Pq+//jrjxo2jTZs2fsdJaGlpaYwfP56nn37a9+kbFb1IgqutreW5555jzJgxXHHFFfTs\n2ZP77rvP71gtwqOPPkpycjL33HOPrzlU9CIJ7v7772fSpEmsXbuWu+++m+XLl9OzZ0+/Y7UI3bt3\nZ/LkycyePZuvv/7atxwqepEE9pe//IWHHnqI2267jY0bN/LYY49pyibGrrzySgD+9a9/+ZZBRS+S\noGbNmsXNN9/MxRdfzDPPPKOjX32Sk5NDamqqr6ctVtGLJKBFixZx4403cuGFF/LOO++Qmprqd6QW\nq3Xr1uTm5qroRSR69u3bxy233ELv3r159913ad++vd+RWrwLLriA/Px8Dh486Mvrq+hFEsj+/fu5\n5ZZb2LZtGy+99BLt2rXzO5IQKvqqqipWrFjhy+ur6EUSRFFREbm5ufz973/nscceY9iwYX5HEs8F\nF1wAwMcff+zL66voRRLEk08+ycaNG5k/fz6TJ0/2O47UkZ2dTd++fVm0aJEvr6+iF0kABw8eZMaM\nGYwZM4bhw4f7HUfqMXLkSBYtWuTLPL2KXiQBvPnmm+zatYvbb7/d7yjSgJEjR1JZWenL/vQqepEE\nMG3aNPr06cPll1/udxRpwCWXXEJKSgp5eXkxf20VvUic27dvH//85z+54YYbSErSf+mg6tChA8OG\nDTui6Pft28e8efPIy8ujuLiYjz76iCVLluCci+prp0T12UQk5hYvXkxNTY0uIhIHRo4cyW9+85tG\nj1K+4IILGDduHKNGjTp8uuOToaIXiXMLFiwgNTVVu1PGgUmTJmFmhy8v2Lp1a84//3wACgoKOPvs\ns9myZQtPPPEEd911FwDXXnstjzzyCGeccUaTX9ei/SdCU+Tm5rr8/Hy/Y4jEpZycHNLS0li4cKHf\nUSSK/v3vfzN9+nSefPJJamtref7557nxxhuPWMfMVjjncht7Lk3oicSxPXv2UFBQwKWXXup3FImy\nHj168MADD7B69WoGDRrETTfdxJNPPklpaSkffvjhCT1Xs0zdmNko4A9AMvCCc+7h5ngdkZZk//79\nzJw5k7y8PNatW4dzjgMHDuCc0/x8Ajv99NP56KOPGD9+PD//+c+ZPHkyzjm++uqriJ8j6kVvZsnA\nM8AIYDuw3MzmOufWRvu1RFqCffv28cwzz/D444+za9cu+vTpw6BBg2jVqhUAWVlZDB061OeU0pxa\ntWrFa6+9xqOPPkpVVRX/8R//QUZGRsRf3xwj+sHAJufcZgAzew24BlDRi5ygOXPmcOutt7J7925G\njx7Nb37zG73p2kKlpKRw7733Nu1ro5wFoBuwrc797cCQ433BmjVrOPvss5shikj8qq2tZf369Zx3\n3nm8//77h/fOEDlRzVH09e0gesyuPWY2EZgI0KZNG84666xmiCIS38aPH8+UKVN04RA5Kc1R9NuB\n0+vc7w7sOHol59w0YBqEdq984403miGKiIg0x+6Vy4G+ZtbLzFKBG4C5zfA6IiISgaiP6J1zh8zs\nJ8A8QrtXznDOrYn264iISGSaZT9659x7wHvN8dwiInJidGSsiEiCU9GLiCQ4Fb2ISIJT0YuIJDgV\nvYhIggvE+ejNrBz43O8cDcgAdvkdoh5BzQXBzRbUXKBsTRHUXBC7bN9yzmU2tlJQrjD1eSQnz/eD\nmeUHMVtQc0FwswU1FyhbUwQ1FwQvm6ZuREQSnIpeRCTBBaXop/kd4DiCmi2ouSC42YKaC5StKYKa\nCwKWLRBvxoqISPMJyoheRESaie9Fb2ajzOxzM9tkZlN8zHG6mS00s3VmtsbMfuYt/y8z+8rMCryP\nK33Kt9XMPvMy5HvLOpnZfDPb6H3uGONM/epslwIz22dmd/m1zcxshpmVmNnqOsvq3UYW8pT3c7fK\nzHJinOsxM1vvvfZbZpbuLe9pZt/U2XbPNVeu42Rr8PtnZr/yttnnZnaFD9lm1cm11cwKvOUx227H\n6Qrff9Ya5Jzz7YPQaYy/AHoDqUAhcJZPWboAOd7t9sAG4Czgv4B7/NxOXqatQMZRyx4Fpni3pwCP\n+Py9/Br4ll/bDLgYyAFWN7aNgCuB9wldEW0osCzGuUYCKd7tR+rk6ll3PZ+2Wb3fP+//QyHQGujl\n/d9NjmW2ox7/b+D+WG+343SF7z9rDX34PaI/fCFx51wVEL6QeMw554qccyu92+XAOkLXvw2ya4CZ\n3u2ZwFgfswwHvnDOfelXAOfcP4A9Ry1uaBtdA7zkQpYC6WbWJVa5nHN5zrlD3t2lhK7EFnMNbLOG\nXAO85pw76JzbAmwi9H845tnMzIBxwF+b6/Ubcpyu8P1nrSF+F319FxL3vVzNrCcwCFjmLfqJ9yfX\njFhPj9ThgDwzW2Gh6+0CZDsYGgKBAAAChUlEQVTniiD0wwdk+ZQNQlcSq/ufLgjbDBreRkH62fvf\nhEZ8Yb3M7FMz+39m9m2fMtX3/QvSNvs2UOyc21hnWcy321FdEdifNb+LPqILiceSmbUD3gTucs7t\nA54F+gDnAkWE/lz0w4XOuRxgNHCnmV3sU45jWOiSkWOA8IV/g7LNjicQP3tm9mvgEPCqt6gI6OGc\nGwRMBv5iZh1iHKuh718gtplnPEcOLGK+3erpigZXrWdZTLeb30Uf0YXEY8XMWhH6xr3qnJsN4Jwr\nds7VOOdqgT/RjH+qHo9zbof3uQR4y8tRHP4T0Ptc4kc2Qr98Vjrnir2Mgdhmnoa2ke8/e2Y2AfgO\ncJPzJnO9aZHd3u0VhObB/1cscx3n++f7NgMwsxTgWmBWeFmst1t9XUGAf9b8LvrAXEjcm/ObDqxz\nzj1eZ3ndubTvAquP/toYZGtrZu3Dtwm9kbea0Laa4K02AZgT62yeI0ZXQdhmdTS0jeYCN3t7RAwF\nysJ/dseCmY0CfgmMcc5V1lmeaWbJ3u3eQF9gc6xyea/b0PdvLnCDmbU2s15etk9imc1zObDeObc9\nvCCW262hriCgP2uAv3vd1HlHegOh38C/9jHHRYT+nFoFFHgfVwIvA595y+cCXXzI1pvQ3g6FwJrw\ndgI6Ax8BG73PnXzI1gbYDaTVWebLNiP0y6YIqCY0irq1oW1E6M/pZ7yfu8+A3Bjn2kRo3jb8s/ac\nt+73vO9xIbASuNqHbdbg9w/4tbfNPgdGxzqbt/zPwO1HrRuz7XacrvD9Z62hDx0ZKyKS4PyeuhER\nkWamohcRSXAqehGRBKeiFxFJcCp6EZEEp6IXEUlwKnoRkQSnohcRSXD/H9s8Jb8IUBsyAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(line_hist),lines[0].shape)\n",
    "print(line_hist)\n",
    "draw_image_histogram(line_hist,lines[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
