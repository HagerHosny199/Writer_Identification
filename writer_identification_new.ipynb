{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import OS to share the project dir\n",
    "import os\n",
    "os.chdir('F:\\\\fourth_year\\Pattern_Classification\\project\\Writer_Identification') \n",
    "\n",
    "#import important packages\n",
    "from IAM_loader import IAM_loader\n",
    "#import tensorflow as tf\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import cv2 as cv2\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage import feature\n",
    "from operator import itemgetter\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import argrelextrema\n",
    "#packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "#allows charts to appear in the notebook \n",
    "%matplotlib inline\n",
    "\n",
    "#ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use IAM handwriting database download it first\n",
    "# here we will read the images and get the important info about the images \n",
    "# we divide the available images into (train,cv and test)\n",
    "# division will be depend on the number of the images \n",
    "\n",
    "training_data=[] # only the train \n",
    "training_data_threshold=[] #training black images \n",
    "test_data_threshold=[] #test black images \n",
    "validation_data=[] # cross validation \n",
    "test_data=[] # test images \n",
    "\n",
    "WIDTH=2175 #image width\n",
    "HEIGHT=2304 #image height\n",
    "path=\"../dataset/output2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reading_and_preprocess():\n",
    "    loader=IAM_loader('../dataset')\n",
    "    training_data,test_data,validation_data = loader.split_data()\n",
    "    #writting the data \n",
    "    training_data_threshold=training_data\n",
    "    test_data_threshold=validation_data\n",
    "    \n",
    "    #getting the thresholded images of the training\n",
    "    for i in range(len(training_data)):\n",
    "            temp=training_data[i][0]\n",
    "            _,image= cv2.threshold(temp,0,255,cv2.THRESH_BINARY_INV)\n",
    "            training_data_threshold[i][0]=image\n",
    "            \n",
    "    #getting the thresholded images of the test\n",
    "    for i in range(len(validation_data)):\n",
    "            temp=validation_data[i][0]\n",
    "            _,image= cv2.threshold(temp,0,255,cv2.THRESH_BINARY_INV)\n",
    "            test_data_threshold[i][0]=image\n",
    "    return training_data,test_data,validation_data,training_data_threshold,test_data_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Module:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the window that contains the words \n",
    "def crop_image(image,y1,y2,x1,x2):\n",
    "    image=image[y1:y2,x1:x2]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#note : use WIDTH and HEIGHT \n",
    "def resize_image (img):\n",
    "    img=cv2.resize(img, dsize=(HEIGHT, WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect lines to get the region of handwritten document: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_lines(img):\n",
    "    horizontal_lines=[]\n",
    "    ret_lines=[] \n",
    "    #apply canny \n",
    "    edges = cv2.Canny(img,50,150,apertureSize = 3)\n",
    "    #dilation\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    img_dilation = cv2.dilate(edges, kernel, iterations=1)\n",
    "    #hough line transform\n",
    "    lines = cv2.HoughLinesP(img_dilation, 1, np.pi/180,200, maxLineGap=1,minLineLength=img.shape[1]/2)\n",
    "    #getting the horizontal lines \n",
    "    for i in range(len(lines)):\n",
    "           for line in lines[i]:\n",
    "                pt1 = (line[0],line[1])\n",
    "                pt2 = (line[2],line[3])\n",
    "                if (line[1]-line[3])==0 : #print((line[2]-line[3])//(line[0]-line[1]))\n",
    "                        cv2.line(img, pt1, pt2, (255,255,255), 3) \n",
    "                        horizontal_lines.append(line)\n",
    "    #sort lines to eleminate the closed lines \n",
    "    horizontal_lines=sorted(horizontal_lines,key=lambda x: x[1])\n",
    "    pt=horizontal_lines[0]\n",
    "    ret_lines.append(pt)\n",
    "    #loop to retrive the included lines \n",
    "    for i in range(1,len(horizontal_lines)):\n",
    "        if abs(horizontal_lines[i][1]-pt[1])>100:\n",
    "            #print(\"included\",horizontal_lines[i])\n",
    "            pt=horizontal_lines[i]\n",
    "            ret_lines.append(pt)\n",
    "    return ret_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the region of handwritten document: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_region():\n",
    "    prev_lines=[]\n",
    "    for i in range(len(training_data)):\n",
    "        img=training_data[i][0]\n",
    "        lines=detect_lines(img)\n",
    "        print(len(lines))\n",
    "        if len(lines)<3:\n",
    "            cropped_img=crop_image(img,prev_lines[1][1]+20,prev_lines[2][1]-3,math.floor(prev_lines[1][0]/4),img.shape[1]-1)\n",
    "            cropped_img=resize_image(cropped_img)\n",
    "            training_data[i][0]=cropped_img\n",
    "        elif len(lines)==3:\n",
    "            cropped_img=crop_image(img,lines[1][1]+10,lines[2][1]-3,math.floor(lines[1][0]/4),img.shape[1]-1)\n",
    "            cropped_img=resize_image(cropped_img)\n",
    "            training_data[i][0]=cropped_img\n",
    "            prev_lines=lines\n",
    "        cv2.imwrite(\"../dataset/cropped/crop\"+str(i)+\".png\",cropped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal projection: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_histogram(img):\n",
    "    histogram=[]\n",
    "    #loop through the image to calcultae the  horizontal histogram of the image\n",
    "    for i in range(img.shape[0]): #for each row\n",
    "        sum=0\n",
    "        for j in range(img.shape[1]): # for each col\n",
    "            if img[i][j]==0:\n",
    "                sum+=1\n",
    "        histogram.append(sum)\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for ploting\n",
    "def draw_image_histogram(hist, width,color='k'):\n",
    "    plt.plot(hist, color=color)\n",
    "    plt.xlim([0, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting local minima: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_local_min(hist):\n",
    "    hist=np.array(hist)\n",
    "    local_minima=argrelextrema(hist, np.less)\n",
    "    return local_minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines segmentation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lines(img,hist,index):\n",
    "    prev_y=0\n",
    "    num=0\n",
    "    lines=[]\n",
    "    line_num=0\n",
    "    for i in range(len(hist)):\n",
    "        if ((i-prev_y)>0 and (num/(i-prev_y))>0.25 and hist[i]==0 and hist[i-1]!=hist[i] and i-prev_y>100) or ((i-prev_y)>0 and (num/(i-prev_y))>0.25 and hist[i]<20 and hist[i-1]<20 and hist[i-1]!=hist[i] and i-prev_y>100) :\n",
    "            temp=img[prev_y:i+5,0:img.shape[1]]\n",
    "            prev_y=i+5\n",
    "            num=0\n",
    "            #cv2.imwrite(\"../dataset/hager/line\"+str(index)+str(line_num)+\".png\",temp)\n",
    "            line_num+=1\n",
    "            lines.append(temp)\n",
    "        elif hist[i]>30:\n",
    "            num+=1\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def line_segmentation(img,num):\n",
    "    im = cv2.erode(img,np.ones((3,200), np.uint8))\n",
    "    im = cv2.medianBlur(im,5)\n",
    "    im = cv2.bitwise_not(im)\n",
    "    w= np.size(img,1)\n",
    "    # cv2.imshow(\"i\",cv2.resize(im,(700,500)))\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    lines = []\n",
    "    _,cnt,_ = cv2.findContours(im,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    for contour in cnt:\n",
    "        x=[c[0] for c in contour.reshape(-1,2)]\n",
    "        y=[c[1] for c in contour.reshape(-1,2)]\n",
    "        minx,miny,maxx,maxy=np.min(x),np.min(y),np.max(x),np.max(y)\n",
    "        if (maxx-minx)>=(0.8*w):\n",
    "            cv2.imwrite(\"../dataset/reem/line\"+str(num)+str(i)+\".png\",img[miny:maxy,minx:maxx])\n",
    "            lines.append(img[miny:maxy,minx:maxx])\n",
    "            i+=1\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the line: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_index(hist):\n",
    "    max=0\n",
    "    index=0\n",
    "    for i in range(len(hist)):\n",
    "        if hist[i]>max:\n",
    "            max=hist[i]\n",
    "            index=i\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_value(hist):\n",
    "    max=0\n",
    "    for i in range(len(hist)):\n",
    "        if hist[i]>max:\n",
    "            max=hist[i]\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaling_line(ideal_hist,hist):\n",
    "    ratio=max_value(ideal_hist)/max_value(hist)\n",
    "    for i in range(len(hist)):\n",
    "        hist[i]=hist[i]*ratio\n",
    "    return hist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting the line: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" this function get the index of the lower baseline to shift by this value \"\"\"\n",
    "def lower_index(hist,value):\n",
    "    index=0\n",
    "    for i in range(len(hist)):\n",
    "        if abs(hist[i]-value)<20:\n",
    "            index=i\n",
    "            break\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shift right the histo by n \n",
    "def shift_right(hist,n):\n",
    "    e = np.empty_like(hist)\n",
    "    if n >= 0:\n",
    "        e[:n] = 0\n",
    "        e[n:] = hist[:-n]\n",
    "    else:\n",
    "        e[n:] = 0\n",
    "        e[:n] = hist[-n:]\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shift left the hist by n\n",
    "def shift_left(hist,n):\n",
    "    e = np.empty_like(hist)\n",
    "    x=len(hist)\n",
    "    if n >= 0:\n",
    "        e[:x-n] = hist[-(x-n):]\n",
    "        e[x-n:] = 0\n",
    "    else:\n",
    "        e[n:] = 0\n",
    "        e[:n] = hist[-n:]\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#control the shift direction based on the diff value\n",
    "def shift(hist,value,ind):\n",
    "    index=lower_index(hist,value)\n",
    "    diff=index-ind\n",
    "    if diff>0:\n",
    "        hist=shift_left(hist,diff)\n",
    "    elif diff<0:\n",
    "        hist=shift_right(hist,-diff)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the top & bottom line: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_bottom(hist):\n",
    "    top=-1\n",
    "    bottom=-1\n",
    "    for i in range(len(hist)):\n",
    "        #getting the bottom\n",
    "        if top!=-1 and hist[i]!=0:\n",
    "            bottom=i\n",
    "        #getting the top\n",
    "        if top==-1 and hist[i]!=0:\n",
    "            top=i\n",
    "    return top,bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the upper & lower baseline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function calculate the ub & lb by doing exhuasitive search by all possible values\n",
    "def upper_lower_baseline(ub,lb,top,bottom,hist,ideal_hist):\n",
    "    prev_err=100000\n",
    "    ub_hist=-1\n",
    "    lb_hist=-1\n",
    "    for u in range(top,len(hist)):\n",
    "        for l in range(u+1,bottom):\n",
    "            err=np.power(((ideal_hist[ub]-hist[u])+(ideal_hist[lb]-hist[l])),2)\n",
    "            if err<prev_err:\n",
    "                prev_err=err\n",
    "                ub_hist=u\n",
    "                lb_hist=l\n",
    "    return ub_hist,lb_hist        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate from f1 to f6: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function do simple calculation after getting the important data \n",
    "def baseline_feature(top,bottom,ub,lb):\n",
    "    f1=abs(top-ub)\n",
    "    f2=abs(ub-lb)\n",
    "    f3=abs(lb-bottom)\n",
    "    f4=f1/f2\n",
    "    f5=f1/f3\n",
    "    f6=f2/f3\n",
    "    return [f1,f2,f3,f4,f5,f6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classiffiers :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM_fun(x,y,x_test):\n",
    "    clf = svm.SVC(gamma=0.01,kernel='rbf')\n",
    "    clf.fit(x, y) \n",
    "    y_test=clf.predict(x_test)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn(X,y,test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh.fit(X, y) \n",
    "    labels_test=neigh.predict(test)\n",
    "    return labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding document a01-000u to the training data\n",
      "Adding document a01-003u to the training data\n",
      "Adding document a01-007u to the training data\n",
      "Adding document a01-011u to the training data\n",
      "Adding document a01-014u to the training data\n",
      "Adding document a01-020u to the training data\n",
      "Adding document a01-026u to the training data\n",
      "Adding document a01-030u to the training data\n",
      "Adding document a01-043u to the training data\n",
      "Adding document a01-049u to the training data\n",
      "Adding document r06-041 to the training data\n",
      "Adding document r06-044 to the training data\n",
      "Adding document r06-049 to the training data\n",
      "Adding document r06-053 to the training data\n",
      "Adding document r06-057 to the training data\n",
      "Adding document r06-062 to the training data\n",
      "Adding document r06-066 to the training data\n",
      "Adding document r06-070 to the training data\n",
      "Adding document r06-076 to the training data\n",
      "Adding document r06-035 to the training data\n",
      "Adding document r06-090 to the training data\n",
      "Adding document r06-097 to the training data\n",
      "Adding document r06-103 to the training data\n",
      "Adding document r06-106 to the training data\n",
      "Adding document r06-111 to the training data\n",
      "Adding document r06-121 to the training data\n",
      "Adding document r06-130 to the training data\n",
      "Adding document r06-137 to the training data\n",
      "Adding document r06-115 to the training data\n"
     ]
    }
   ],
   "source": [
    "training_data,test_data,validation_data,training_data_threshold,test_data_threshold=reading_and_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "get_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 183 115 162\n",
      "0 204 109 148\n",
      "88 173 101 147\n",
      "103 145 104 138\n",
      "102 196 149 172\n",
      "93 151 113 145\n",
      "0 180 96 146\n",
      "0 88 200 95 146\n",
      "83 181 156 166\n",
      "93 187 113 146\n",
      "80 171 102 157\n",
      "92 188 96 156\n",
      "0 200 98 150\n",
      "81 190 117 147\n",
      "84 164 100 151\n",
      "0 177 113 147\n",
      "88 185 101 143\n",
      "73 186 148 175\n",
      "1 97 176 109 153\n",
      "68 137 91 103\n",
      "92 174 100 153\n",
      "86 183 104 148\n",
      "85 173 129 165\n",
      "62 150 64 105\n",
      "91 171 96 139\n",
      "95 189 152 176\n",
      "85 190 91 143\n",
      "15 159 103 152\n",
      "2 72 186 154 169\n",
      "92 171 121 147\n",
      "81 193 121 139\n",
      "3 180 125 135\n",
      "6 176 137 166\n",
      "82 182 100 141\n",
      "1 198 121 154\n",
      "95 195 120 154\n",
      "101 160 109 148\n",
      "84 190 95 139\n",
      "3 44 167 107 165\n",
      "93 205 120 140\n",
      "91 141 109 140\n",
      "95 188 116 147\n",
      "87 164 91 140\n",
      "89 191 124 142\n",
      "88 181 101 145\n",
      "100 170 101 143\n",
      "99 168 103 148\n",
      "4 96 175 102 149\n",
      "94 181 148 173\n",
      "105 169 150 165\n",
      "96 173 149 170\n",
      "94 201 125 137\n",
      "94 175 154 165\n",
      "92 189 143 188\n",
      "97 179 120 148\n",
      "94 159 118 135\n",
      "88 168 89 151\n",
      "5 95 192 117 152\n",
      "0 179 117 141\n",
      "62 145 71 108\n",
      "93 188 121 141\n",
      "93 182 153 174\n",
      "83 202 105 150\n",
      "86 176 89 142\n",
      "73 196 146 172\n",
      "93 182 131 157\n",
      "88 177 101 153\n",
      "2 181 116 138\n",
      "6 90 174 96 152\n",
      "106 168 118 142\n",
      "92 191 102 141\n",
      "98 185 120 144\n",
      "89 172 125 145\n",
      "7 167 124 149\n",
      "90 172 94 138\n",
      "83 194 150 170\n",
      "84 179 95 149\n",
      "89 199 151 162\n",
      "99 158 116 141\n",
      "7 83 172 121 154\n",
      "102 185 112 141\n",
      "86 176 94 146\n",
      "103 178 122 139\n",
      "0 189 129 134\n",
      "7 172 136 165\n",
      "92 181 128 155\n",
      "0 172 108 142\n",
      "87 185 102 141\n",
      "8 55 173 130 132\n",
      "0 192 103 145\n",
      "0 170 88 152\n",
      "107 193 156 190\n",
      "25 178 28 147\n",
      "95 194 119 145\n",
      "27 176 122 160\n",
      "87 207 140 205\n",
      "48 150 52 102\n",
      "95 188 123 159\n",
      "91 197 116 163\n",
      "9 35 192 110 164\n",
      "51 141 69 140\n",
      "18 180 121 162\n",
      "98 180 108 143\n",
      "17 191 121 140\n",
      "0 153 23 107\n",
      "47 168 165 166\n",
      "10 130 244 130 240\n",
      "49 144 118 141\n",
      "15 189 114 178\n",
      "10 224 136 187\n",
      "44 150 113 143\n",
      "7 196 116 164\n",
      "17 192 84 152\n",
      "21 245 21 171\n",
      "9 226 92 153\n",
      "44 187 48 160\n",
      "11 86 185 102 170\n",
      "5 198 101 166\n",
      "26 177 108 144\n",
      "15 217 99 145\n",
      "54 185 67 165\n",
      "60 142 120 137\n",
      "27 191 29 164\n",
      "43 167 43 159\n",
      "22 210 114 156\n",
      "57 180 62 163\n",
      "43 197 114 184\n",
      "12 72 229 157 218\n",
      "54 146 130 133\n",
      "26 182 108 174\n",
      "28 216 125 138\n",
      "57 145 119 143\n",
      "26 172 102 149\n",
      "17 202 110 143\n",
      "44 167 46 156\n",
      "28 178 39 156\n",
      "13 28 199 113 143\n",
      "16 190 85 162\n",
      "29 162 103 146\n",
      "21 189 111 154\n",
      "91 174 99 159\n",
      "30 182 96 158\n",
      "36 183 52 155\n",
      "54 184 54 163\n",
      "61 130 128 129\n",
      "14 89 184 109 156\n",
      "20 198 22 163\n",
      "39 175 122 166\n",
      "48 198 159 192\n",
      "71 130 128 129\n",
      "23 174 24 164\n",
      "79 191 102 160\n",
      "43 153 65 150\n",
      "1 205 97 162\n",
      "15 52 182 90 151\n",
      "12 190 27 173\n",
      "16 179 102 161\n",
      "21 177 21 171\n",
      "21 178 26 170\n",
      "18 252 109 156\n",
      "34 169 84 155\n",
      "25 173 110 139\n",
      "42 216 55 105\n",
      "16 90 211 144 200\n",
      "37 170 110 147\n",
      "35 167 107 148\n",
      "14 196 37 162\n",
      "33 192 118 148\n",
      "42 206 54 156\n",
      "72 131 129 130\n",
      "16 190 114 154\n",
      "0 155 54 93\n",
      "40 152 50 142\n",
      "17 96 201 102 176\n",
      "19 188 21 146\n",
      "21 215 39 167\n",
      "64 142 113 139\n",
      "21 171 31 152\n",
      "18 178 123 134\n",
      "18 104 183 106 161\n",
      "11 179 11 162\n",
      "15 174 107 163\n",
      "20 168 55 167\n",
      "12 176 100 158\n",
      "9 212 135 179\n",
      "7 140 62 100\n",
      "19 0 168 102 142\n",
      "80 178 94 153\n",
      "0 178 113 148\n",
      "0 171 30 146\n",
      "87 174 131 157\n",
      "0 172 21 139\n",
      "0 171 117 143\n",
      "0 169 90 143\n",
      "20 53 159 115 149\n",
      "45 144 61 123\n",
      "83 167 118 150\n",
      "0 142 93 104\n",
      "0 166 98 133\n",
      "0 173 81 136\n",
      "0 170 93 145\n",
      "0 171 89 138\n",
      "0 159 125 150\n",
      "7 163 109 136\n",
      "21 0 171 86 148\n",
      "0 170 3 147\n",
      "0 170 99 137\n",
      "0 173 99 138\n",
      "0 161 97 110\n",
      "14 164 147 161\n",
      "22 0 220 95 145\n",
      "0 146 99 113\n",
      "78 177 93 143\n",
      "61 146 110 137\n",
      "59 142 71 123\n",
      "0 163 2 147\n",
      "0 210 100 143\n",
      "23 81 168 82 144\n",
      "88 187 94 141\n",
      "6 166 86 148\n",
      "0 169 120 142\n",
      "0 178 89 150\n",
      "10 164 145 159\n",
      "2 166 9 135\n",
      "24 53 147 72 122\n",
      "0 171 109 143\n",
      "0 171 97 147\n",
      "0 170 3 137\n",
      "0 167 22 144\n",
      "0 168 113 148\n",
      "0 165 105 143\n",
      "85 169 117 142\n",
      "0 170 95 153\n",
      "0 208 131 156\n",
      "1 160 61 124\n",
      "25 73 168 103 139\n",
      "83 172 119 149\n",
      "0 181 103 142\n",
      "0 178 140 161\n",
      "0 188 103 125\n",
      "83 130 128 129\n",
      "0 172 101 146\n",
      "88 165 111 141\n",
      "0 193 11 142\n",
      "26 81 166 107 138\n",
      "53 153 69 115\n",
      "0 144 69 121\n",
      "0 168 95 142\n",
      "0 169 93 139\n",
      "0 168 108 144\n",
      "0 190 145 179\n",
      "0 168 3 148\n",
      "0 172 142 163\n",
      "0 171 27 147\n",
      "27 78 159 117 151\n",
      "0 173 20 138\n",
      "84 168 86 136\n",
      "0 165 13 140\n",
      "71 181 145 158\n",
      "2 186 38 153\n",
      "0 172 85 141\n",
      "0 189 27 139\n",
      "6 160 21 143\n",
      "0 183 94 146\n",
      "28 "
     ]
    }
   ],
   "source": [
    "F=[]\n",
    "labels=[]\n",
    "#getting the ideal hist \n",
    "img=cv2.imread(\"../dataset/ideal.png\")\n",
    "#convert to gray scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "ideal_hist=get_histogram(img)\n",
    "\n",
    "for i in range(len(training_data)):\n",
    "    img=training_data[i][0]\n",
    "    #getting the binary image\n",
    "    ret,img = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "    #calculate the histogram\n",
    "    hist=get_histogram(img)\n",
    "    lines=get_lines(img,hist,i)\n",
    "    for j in range(len(lines)):\n",
    "        line_hist=get_histogram(lines[j])\n",
    "        line_hist=scaling_line(ideal_hist,line_hist)\n",
    "        line_hist=shift(line_hist,352,130)\n",
    "        top,bottom=top_bottom(line_hist)\n",
    "        ub,lb=upper_lower_baseline(160,132,top,bottom,line_hist,ideal_hist)\n",
    "        if ub!=-1 and lb!=-1:\n",
    "            f=baseline_feature(top,bottom,ub,lb)\n",
    "            F.append(f)\n",
    "            labels.append(training_data[i][1])\n",
    "    print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features=[]\n",
    "training_labels=[]\n",
    "test_features=[]\n",
    "test_labels=[]\n",
    "for i in range(len(F)):\n",
    "    if i%10==0:\n",
    "        test_features.append(F[i])\n",
    "        test_labels.append(labels[i])\n",
    "        test_features.append(F[i+1])\n",
    "        test_labels.append(labels[i+1])\n",
    "        i+=1\n",
    "    else:\n",
    "        training_features.append(F[i])\n",
    "        training_labels.append(labels[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['671' '000' '000' '000' '000' '000' '000' '000' '000' '000' '670' '000'\n",
      " '000' '000' '000' '000' '670' '000' '670' '000' '670' '670' '000' '670'\n",
      " '670' '670' '671' '670' '000' '670' '670' '670' '670' '670' '671' '670'\n",
      " '671' '670' '000' '671' '671' '671' '671' '671' '671' '671' '671' '671'\n",
      " '670' '671' '671' '671' '671' '671']\n",
      "['000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671']\n",
      "43 54 0.7962962962962963\n"
     ]
    }
   ],
   "source": [
    "ret_labels=knn(training_features,training_labels,test_features)\n",
    "print(ret_labels)\n",
    "print(test_labels)\n",
    "count=0\n",
    "for i in range(len(ret_labels)):\n",
    "    if ret_labels[i]==test_labels[i]:\n",
    "        count+=1\n",
    "print(count,len(ret_labels),count/len(ret_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '000' '000' '000' '000' '000' '000' '000' '670' '000' '670' '000'\n",
      " '000' '000' '000' '000' '000' '000' '670' '000' '670' '670' '000' '670'\n",
      " '670' '670' '670' '670' '000' '670' '670' '670' '670' '670' '671' '670'\n",
      " '671' '670' '000' '671' '671' '671' '670' '671' '671' '671' '671' '000'\n",
      " '670' '671' '670' '671' '671' '671']\n",
      "['000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '000', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '670', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671', '671']\n",
      "264\n",
      "42 54 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "ret_labels=SVM_fun(training_features,training_labels,test_features)\n",
    "print(ret_labels)\n",
    "print(test_labels)\n",
    "print(len(F))\n",
    "count=0\n",
    "for i in range(len(ret_labels)):\n",
    "    if ret_labels[i]==test_labels[i]:\n",
    "        count+=1\n",
    "print(count,len(ret_labels),count/len(ret_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(F)):\n",
    "    if labels[i]=='588':\n",
    "        print(F[i])\n",
    "print(\"test\")\n",
    "for i in range(len(ret_labels)):\n",
    "    if test_labels[i]=='588':\n",
    "        print(test_features[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
